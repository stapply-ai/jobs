# ğŸš€ Stapply Map

<div align="center">

**An open-source map of the jobs**

</div>

---

## Map

We built a map of the jobs:

- [Explore the interactive job map](https://map.stapply.ai)

![Preview of the Stapply job map](job-map/public/opengraph-image.jpeg)


## ğŸ“Š Public Data

The aggregated job data is available at: **https://storage.stapply.ai/jobs.csv**

This CSV is updated regularly and contains job postings from all supported platforms.

## âœ¨ Features

- **ğŸŒ Multi-Platform Support** - Scrape jobs from 5+ different ATS platforms (Ashby, Greenhouse, Lever, Workable, Rippling)
- **ğŸ” Smart Discovery** - Multiple discovery methods to find companies using ATS platforms
- **ğŸ“¦ Structured Data** - Clean, normalized job data with consistent schema across platforms
- **ğŸ”„ Incremental Processing** - Checkpoint system prevents duplicate processing
- **ğŸ“ˆ Job Lifecycle Tracking** - Automatically detect and mark inactive jobs
- **ğŸ¯ Semantic Search** - OpenAI embeddings for job title and description (Ashby)
- **ğŸ³ Self-Hosted Options** - Use SearXNG for unlimited discovery without API limits
- **ğŸ“ Export Formats** - CSV exports with automatic diff tracking for new/updated jobs

## ğŸ—ï¸ Architecture

The project follows a modular, platform-based architecture:

```
data/
â”œâ”€â”€ ğŸ“ Platform Modules (ashby/, greenhouse/, lever/, workable/)
â”‚   â”œâ”€â”€ main.py              # Platform-specific scraper
â”‚   â”œâ”€â”€ export_to_csv.py     # CSV export utility
â”‚   â”œâ”€â”€ companies/           # JSON files (one per company)
â”‚   â”œâ”€â”€ jobs.csv             # Platform-specific job export
â”‚   â””â”€â”€ *_companies.csv      # Company URL registry
â”‚
â”œâ”€â”€ ğŸ“ Core Components
â”‚   â”œâ”€â”€ models/              # Pydantic data models for each platform
â”‚   â”œâ”€â”€ classifier/          # Job classification tools
â”‚   â”œâ”€â”€ searxng-docker/      # SearXNG self-hosted setup
â”‚   â””â”€â”€ gather_jobs.py       # Job consolidation utility
â”‚
â”œâ”€â”€ ğŸ” Discovery Scripts
â”‚   â”œâ”€â”€ searxng_discovery.py      # Self-hosted search (unlimited!)
â”‚   â”œâ”€â”€ discovery.py              # Discovery utilities
â”‚   â””â”€â”€ [other discovery methods]
â”‚
â””â”€â”€ ğŸ“„ Configuration
    â”œâ”€â”€ pyproject.toml       # Python dependencies
    â”œâ”€â”€ env.example           # Environment variables template
    â””â”€â”€ README.md            # This file
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.12+
- [uv](https://github.com/astral-sh/uv) (recommended) or pip
- PostgreSQL (optional, for database processing)
- SearXNG instance (optional, for unlimited discovery)

### Installation

```bash
# Clone the repository
git clone https://github.com/stapply-ai/data.git
cd data

# Install dependencies using uv (recommended)
uv sync

# Or using pip
pip install -r requirements.txt
```

### Environment Setup

Create a `.env` file from the example:

```bash
cp env.example .env
```

Edit `.env` with your configuration:

```env
# Required for job processing and embeddings
DATABASE_URL=postgresql://user:pass@host:port/dbname
OPENAI_API_KEY=sk-...

# Optional: Discovery methods
SEARXNG_URL=http://localhost:8080        # Self-hosted search (unlimited!)
SERPAPI_API_KEY=your_serpapi_key        # SerpAPI for discovery
FIRECRAWL_API_KEY=fc-your_key           # Firecrawl search API
GOOGLE_API_KEY=your_google_key          # Google Custom Search API
GOOGLE_CSE_ID=your_cse_id               # Custom Search Engine ID
BING_API_KEY=your_bing_key              # Bing Search API
```

## ğŸ“– Usage

### Job Scraping

Scrape jobs from discovered companies:

```bash
# Ashby
cd ashby
python main.py              # Scrapes jobs to companies/ directory as JSON
python export_to_csv.py     # Exports jobs from JSON to jobs.csv
```

### Consolidate Jobs

Merge all platform CSVs into a single file:

```bash
python gather_jobs.py
```

This creates a unified `jobs.csv` at the root with jobs from all platforms.

## ğŸ“ License

This project is open source. Contributions are welcome!

## ğŸŒ Links

- **Public Jobs CSV**: https://storage.stapply.ai/jobs.csv
- **Website**: https://stapply.ai
- **Issues**: [GitHub Issues](https://github.com/stapply-ai/data/issues)